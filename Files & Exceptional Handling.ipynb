{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86f0e085-3cca-4e34-8ed0-cb6446150131",
   "metadata": {},
   "source": [
    "**Q. 1. Discuss the scenarios where multithreading is preferable to multiprocessing and scenarios where multiprocessing is a better choice.**\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "Multithreading\n",
    "Multithreading is preferable in scenarios where tasks are I/O-bound. This means the tasks spend a lot of time waiting for input/output operations to complete, such as reading from a file, network operations, or database queries. Here are some specific scenarios:\n",
    "\n",
    "1. Web Scraping: When scraping data from multiple web pages, threads can be used to fetch data concurrently, reducing the overall time.\n",
    "2. GUI Applications: In applications with graphical user interfaces, multithreading can keep the interface responsive while performing background tasks.\n",
    "3. Network Servers: Handling multiple client connections simultaneously can be efficiently managed using threads.\n",
    "4. File I/O Operations: Reading from or writing to multiple files concurrently can be sped up using threads.\n",
    "\n",
    "Multiprocessing\n",
    "Multiprocessing is better suited for CPU-bound tasks, which are tasks that require a lot of computation and can benefit from parallel execution. Here are some scenarios where multiprocessing shines:\n",
    "\n",
    "1. Data Processing: Tasks like image processing, video rendering, or large-scale numerical computations can be parallelized across multiple processors.\n",
    "2. Machine Learning: Training models on large datasets can be distributed across multiple CPUs to speed up the process.\n",
    "3. Scientific Simulations: Simulations that require heavy computations can be divided into smaller tasks and run in parallel.\n",
    "4. Parallel Algorithms: Algorithms that can be broken down into independent tasks, such as sorting large datasets or matrix multiplications, can benefit from multiprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83131adf-38f1-4e81-9a1e-c54361ada142",
   "metadata": {},
   "source": [
    "**Q.2 Describe what a process pool is and how it helps in managing multiple processes efficiently.**\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "A process pool is a collection of worker processes that are managed by a pool manager to execute tasks concurrently. It is a powerful tool for parallel processing, especially useful when you need to perform a large number of CPU-bound tasks. Here’s how it helps in managing multiple processes efficiently:\n",
    "\n",
    "Key Features of a Process Pool\n",
    "1. Task Distribution: The pool manager distributes tasks among the available worker processes. This ensures that all processes are utilized efficiently, and no single process is overloaded.\n",
    "2. Resource Management: By limiting the number of processes, a process pool helps in managing system resources effectively. It prevents the system from being overwhelmed by too many processes running simultaneously.\n",
    "3. Simplified API: Libraries like Python’s multiprocessing module provide a simplified API for creating and managing process pools, making it easier to implement parallel processing.\n",
    "\n",
    "How It Works\n",
    "1. Initialization: A process pool is initialized with a specified number of worker processes.\n",
    "2. Task Submission: Tasks are submitted to the pool, which queues them up for execution.\n",
    "3. Task Execution: The pool manager assigns tasks to idle worker processes. Once a worker completes a task, it becomes available for the next task.\n",
    "4. Result Collection: The results of the tasks are collected and returned to the main process.\n",
    "5. \n",
    "Benefits\n",
    "* Efficiency: By reusing worker processes, a process pool reduces the overhead of creating and destroying processes for each task.\n",
    "* Scalability: It allows for easy scaling of applications by simply adjusting the number of worker processes in the pool.\n",
    "* Load Balancing: The pool manager ensures that tasks are evenly distributed among the worker processes, leading to better load balancing.\n",
    "Example in Python\n",
    "Here’s a simple example using Python’s multiprocessing.Pool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adae969b-6c08-446f-bc73-f73f06ad0689",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "def square(x):\n",
    "    return x * x\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with Pool(4) as p:  # Create a pool with 4 worker processes\n",
    "        results = p.map(square, [1, 2, 3, 4, 5])\n",
    "    print(results)  # Output: [1, 4, 9, 16, 25]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045ae122-b1be-47b4-aa18-5b616317d96b",
   "metadata": {},
   "source": [
    "**Q.3 Explain what multiprocessing is and why it is used in Python programs.**\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "Multiprocessing is a technique in computer programming where multiple processes are run simultaneously to perform tasks. Each process runs independently and has its own memory space. This is particularly useful for CPU-bound tasks that require significant computational power.\n",
    "\n",
    "Why Use Multiprocessing in Python?\n",
    "1. Bypassing the Global Interpreter Lock (GIL): Python’s GIL allows only one thread to execute at a time, which can be a bottleneck for CPU-bound tasks. Multiprocessing creates separate processes, each with its own Python interpreter and memory space, effectively bypassing the GIL and allowing true parallel execution.\n",
    "2. Improved Performance: By distributing tasks across multiple CPU cores, multiprocessing can significantly speed up the execution of CPU-intensive tasks. This is especially beneficial for tasks like data processing, scientific computations, and machine learning model training.\n",
    "3. Scalability: Multiprocessing allows programs to scale efficiently by utilizing multiple cores of modern CPUs. This makes it easier to handle large datasets and perform complex computations.\n",
    "4. Isolation: Each process runs in its own memory space, which provides isolation and reduces the risk of memory corruption and other issues that can arise with multithreading.\n",
    "Example in Python\n",
    "Here’s a simple example using Python’s multiprocessing module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efa8789-ff81-4fa4-a48d-57f7a6265c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process\n",
    "\n",
    "def print_square(num):\n",
    "    print(f'Square: {num * num}')\n",
    "\n",
    "def print_cube(num):\n",
    "    print(f'Cube: {num * num * num}')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    p1 = Process(target=print_square, args=(10,))\n",
    "    p2 = Process(target=print_cube, args=(10,))\n",
    "\n",
    "    p1.start()\n",
    "    p2.start()\n",
    "\n",
    "    p1.join()\n",
    "    p2.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf982e69-54de-45ce-bcd5-54c91a13c38d",
   "metadata": {},
   "source": [
    "In this example, two processes are created to compute the square and cube of a number concurrently. Each process runs independently, allowing both tasks to be executed in parallel.\n",
    "\n",
    "When to Use Multiprocessing\n",
    "* CPU-bound tasks: Tasks that require heavy computation, such as numerical simulations, data analysis, and image processing.\n",
    "* Parallel algorithms: Algorithms that can be divided into independent tasks, such as sorting large datasets or matrix multiplications.\n",
    "* Large-scale data processing: Handling and processing large datasets efficiently by distributing the workload across multiple processes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc35c8b-d5f1-476c-8eb3-8e42c5f87b53",
   "metadata": {},
   "source": [
    "**Q. 4 Write a Python program using multithreading where one thread adds numbers to a list, and another thread removes numbers from the list. Implement a mechanism to avoid race conditions using threading.Lock.**\n",
    "\n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c725b1-67f1-45fd-9e08-c20c5db77d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "# Shared resource\n",
    "numbers = []\n",
    "\n",
    "# Lock to prevent race conditions\n",
    "lock = threading.Lock()\n",
    "\n",
    "def add_numbers():\n",
    "    for i in range(10):\n",
    "        time.sleep(1)  # Simulate some delay\n",
    "        with lock:\n",
    "            numbers.append(i)\n",
    "            print(f\"Added {i}, List: {numbers}\")\n",
    "\n",
    "def remove_numbers():\n",
    "    for i in range(10):\n",
    "        time.sleep(1.5)  # Simulate some delay\n",
    "        with lock:\n",
    "            if numbers:\n",
    "                removed = numbers.pop(0)\n",
    "                print(f\"Removed {removed}, List: {numbers}\")\n",
    "\n",
    "# Create threads\n",
    "thread1 = threading.Thread(target=add_numbers)\n",
    "thread2 = threading.Thread(target=remove_numbers)\n",
    "\n",
    "# Start threads\n",
    "thread1.start()\n",
    "thread2.start()\n",
    "\n",
    "# Wait for threads to complete\n",
    "thread1.join()\n",
    "thread2.join()\n",
    "\n",
    "print(\"Final List:\", numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f6f1ec-1562-465a-9455-83c1e5eb67c9",
   "metadata": {},
   "source": [
    "Explanation\n",
    "1. Shared Resource: The numbers list is shared between the two threads.\n",
    "2. Lock: A threading.Lock object is used to ensure that only one thread can modify the list at a time, preventing race conditions.\n",
    "3. Add Numbers: The add_numbers function adds numbers to the list with a delay to simulate work.\n",
    "4. Remove Numbers: The remove_numbers function removes numbers from the list with a slightly longer delay to simulate work.\n",
    "5. Threads: Two threads are created, one for adding numbers and one for removing numbers.\n",
    "6. Synchronization: The with lock statement ensures that the list operations are thread-safe.\n",
    "    \n",
    "Output\n",
    "\n",
    "The program will output the state of the list as numbers are added and removed, ensuring that the operations are synchronized and no race conditions occur."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e82a31-c36b-469e-8dd5-8262d9528f1c",
   "metadata": {},
   "source": [
    "**Q. 5 Describe the methods and tools available in Python for safely sharing data between threads and processes.**\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "In Python, safely sharing data between threads and processes is crucial to avoid race conditions and ensure data integrity. Here are some methods and tools available for this purpose:\n",
    "\n",
    "**Sharing Data Between Threads**\n",
    "1. threading.Lock:\n",
    "* Purpose: Ensures that only one thread can access a shared resource at a time.\n",
    "* Usage: Use lock.acquire() to lock and lock.release() to unlock. Alternatively, use the with lock: statement for automatic handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c5e8fc-d65f-435d-b5c3-2b5b4e093201",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "lock = threading.Lock()\n",
    "shared_data = []\n",
    "\n",
    "def thread_safe_append(data):\n",
    "    with lock:\n",
    "        shared_data.append(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d84844-386b-4de2-b0e9-654f0103212f",
   "metadata": {},
   "source": [
    "2. threading.Event:\n",
    "* Purpose: Used for signaling between threads.\n",
    "* Usage: Use event.set() to signal and event.wait() to wait for the signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec4895d-d980-40e3-9bfe-ec37cf2737d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "event = threading.Event()\n",
    "\n",
    "def wait_for_event():\n",
    "    event.wait()\n",
    "    print(\"Event received!\")\n",
    "\n",
    "threading.Thread(target=wait_for_event).start()\n",
    "event.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52b2880-b469-44c8-894b-dade1e269f09",
   "metadata": {},
   "source": [
    "3. queue.Queue:\n",
    "* urpose: Provides a thread-safe FIFO queue.\n",
    "* Usage: Use queue.put() to add items and queue.get() to retrieve items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1b94f0-ce00-42f2-8850-46b4b91d8c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import queue\n",
    "\n",
    "q = queue.Queue()\n",
    "\n",
    "def producer():\n",
    "    for i in range(5):\n",
    "        q.put(i)\n",
    "        print(f\"Produced {i}\")\n",
    "\n",
    "def consumer():\n",
    "    while not q.empty():\n",
    "        item = q.get()\n",
    "        print(f\"Consumed {item}\")\n",
    "\n",
    "threading.Thread(target=producer).start()\n",
    "threading.Thread(target=consumer).start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814c5236-b84b-4d32-915c-56485d941f6b",
   "metadata": {},
   "source": [
    "**Sharing Data Between Processes**\n",
    "\n",
    "1. multiprocessing.Queue:\n",
    "*Purpose: Provides a process-safe FIFO queue.\n",
    "*Usage: Similar to queue.Queue, but for processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92efa6f4-cd54-4344-81d0-36a9c1c3bc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Queue\n",
    "\n",
    "def producer(q):\n",
    "    for i in range(5):\n",
    "        q.put(i)\n",
    "        print(f\"Produced {i}\")\n",
    "\n",
    "def consumer(q):\n",
    "    while not q.empty():\n",
    "        item = q.get()\n",
    "        print(f\"Consumed {item}\")\n",
    "\n",
    "q = Queue()\n",
    "p1 = Process(target=producer, args=(q,))\n",
    "p2 = Process(target=consumer, args=(q,))\n",
    "\n",
    "p1.start()\n",
    "p2.start()\n",
    "\n",
    "p1.join()\n",
    "p2.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4409a828-4883-411e-b7ab-48de03d83408",
   "metadata": {},
   "source": [
    "2. multiprocessing.Pipe:\n",
    "* Purpose: Provides a two-way communication channel between processes.\n",
    "* Usage: Use pipe.send() to send data and pipe.recv() to receive data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45f83b3-c809-4fc4-bc6a-997719782ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Pipe\n",
    "\n",
    "def sender(conn):\n",
    "    conn.send(\"Hello from the sender!\")\n",
    "    conn.close()\n",
    "\n",
    "def receiver(conn):\n",
    "    print(conn.recv())\n",
    "    conn.close()\n",
    "\n",
    "parent_conn, child_conn = Pipe()\n",
    "p1 = Process(target=sender, args=(child_conn,))\n",
    "p2 = Process(target=receiver, args=(parent_conn,))\n",
    "\n",
    "p1.start()\n",
    "p2.start()\n",
    "\n",
    "p1.join()\n",
    "p2.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae626f0-b7c7-4bd6-9336-4c5e11cd1d05",
   "metadata": {},
   "source": [
    "3. multiprocessing.Value and multiprocessing.Array:\n",
    "* Purpose: Share simple data types and arrays between processes.\n",
    "* Usage: Use Value for single values and Array for arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6783c1af-0f66-480f-a785-9c4e64726162",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Value, Array\n",
    "\n",
    "def modify_value(val):\n",
    "    val.value += 1\n",
    "\n",
    "def modify_array(arr):\n",
    "    for i in range(len(arr)):\n",
    "        arr[i] += 1\n",
    "\n",
    "shared_value = Value('i', 0)\n",
    "shared_array = Array('i', [0, 1, 2, 3, 4])\n",
    "\n",
    "p1 = Process(target=modify_value, args=(shared_value,))\n",
    "p2 = Process(target=modify_array, args=(shared_array,))\n",
    "\n",
    "p1.start()\n",
    "p2.start()\n",
    "\n",
    "p1.join()\n",
    "p2.join()\n",
    "\n",
    "print(shared_value.value)  # Output: 1\n",
    "print(shared_array[:])    # Output: [1, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83cd5cc-0420-43f0-b1a2-9740003b793b",
   "metadata": {},
   "source": [
    "**Q. 6 Discuss why it's crucial to handle exceptions in concurrent programs and the techniques available for doing so.**\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "Why It’s Crucial\n",
    "1. Maintaining Program Stability: Unhandled exceptions can cause threads or processes to terminate unexpectedly, leading to partial or complete failure of the application.\n",
    "2. Data Integrity: Concurrent programs often share resources. Unhandled exceptions can leave shared resources in an inconsistent state, causing data corruption.\n",
    "3. Debugging and Maintenance: Properly handling exceptions makes it easier to diagnose and fix issues. It provides clear error messages and stack traces, which are essential for debugging.\n",
    "4. Graceful Degradation: Handling exceptions allows the program to continue running or shut down gracefully, rather than crashing abruptly.\n",
    "5. Resource Management: Ensuring that resources (like file handles, network connections, etc.) are properly released even when errors occur is critical in concurrent environments.\n",
    "   \n",
    "**Techniques for Handling Exceptions**\n",
    "1. Try-Except Blocks:\n",
    "* Usage: Surround critical sections of code with try-except blocks to catch and handle exceptions.\n",
    "* Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25f812a-4359-4fe5-bd88-813f960459c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "def thread_function():\n",
    "    try:\n",
    "        # Critical section\n",
    "        pass\n",
    "    except Exception as e:\n",
    "        print(f\"Exception occurred: {e}\")\n",
    "\n",
    "thread = threading.Thread(target=thread_function)\n",
    "thread.start()\n",
    "thread.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718cfd29-5d35-4b10-aceb-f03994b81d35",
   "metadata": {},
   "source": [
    "2. Thread-Safe Queues:\n",
    "* Purpose: Use queues to safely pass exceptions from worker threads to the main thread.\n",
    "  \n",
    "Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4bcf7d-a748-4969-89d2-0785c52a07a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import queue\n",
    "\n",
    "def worker(q):\n",
    "    try:\n",
    "        # Critical section\n",
    "        pass\n",
    "    except Exception as e:\n",
    "        q.put(e)\n",
    "\n",
    "q = queue.Queue()\n",
    "thread = threading.Thread(target=worker, args=(q,))\n",
    "thread.start()\n",
    "thread.join()\n",
    "\n",
    "if not q.empty():\n",
    "    exception = q.get()\n",
    "    print(f\"Exception occurred: {exception}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a62d9f-b34f-4f76-b96c-541e51b8d151",
   "metadata": {},
   "source": [
    "3. Context Managers:\n",
    "* Purpose: Use context managers to ensure that resources are properly managed and exceptions are handled.\n",
    "* \n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa05f00-74ab-44da-ae4f-cff5788a6659",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def managed_resource():\n",
    "    try:\n",
    "        # Setup resource\n",
    "        yield\n",
    "    except Exception as e:\n",
    "        print(f\"Exception occurred: {e}\")\n",
    "    finally:\n",
    "        # Cleanup resource\n",
    "        pass\n",
    "\n",
    "with managed_resource():\n",
    "    # Critical section\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fab58cb-f3b7-42a5-8e8a-7b11dd4f3d39",
   "metadata": {},
   "source": [
    "4. Custom Exception Classes:\n",
    "* Purpose: Define custom exception classes to handle specific types of errors more effectively.\n",
    "* \n",
    "Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba8a637-1145-40a8-a9e0-cbdaa18bb007",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomException(Exception):\n",
    "    pass\n",
    "\n",
    "def thread_function():\n",
    "    try:\n",
    "        # Critical section\n",
    "        raise CustomException(\"An error occurred\")\n",
    "    except CustomException as e:\n",
    "        print(f\"Custom exception caught: {e}\")\n",
    "\n",
    "thread = threading.Thread(target=thread_function)\n",
    "thread.start()\n",
    "thread.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09981819-3578-4143-afd0-c3555468c362",
   "metadata": {},
   "source": [
    "5. Exception Propagation:\n",
    "* Purpose: Propagate exceptions from worker threads to the main thread for centralized handling.\n",
    "\n",
    "Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f8f0675-3772-4393-8612-a8712ca11fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "def worker():\n",
    "    try:\n",
    "        # Critical section\n",
    "        pass\n",
    "    except Exception as e:\n",
    "        threading.current_thread().exception = e\n",
    "\n",
    "thread = threading.Thread(target=worker)\n",
    "thread.start()\n",
    "thread.join()\n",
    "\n",
    "if hasattr(thread, 'exception'):\n",
    "    print(f\"Exception occurred: {thread.exception}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12118403-bec6-4fba-abae-8491a3234cc5",
   "metadata": {},
   "source": [
    "**Q. 7 Create a program that uses a thread pool to calculate the factorial of numbers from 1 to 10 concurrently. Use concurrent.futures.ThreadPoolExecutor to manage the threads.**\n",
    "\n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ff4b7d-d8c9-4b64-bb60-af7caeeb85f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "def factorial(n):\n",
    "    if n == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        result = 1\n",
    "        for i in range(1, n + 1):\n",
    "            result *= i\n",
    "        return result\n",
    "\n",
    "def main():\n",
    "    numbers = range(1, 11)\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        results = list(executor.map(factorial, numbers))\n",
    "    \n",
    "    for number, result in zip(numbers, results):\n",
    "        print(f\"Factorial of {number} is {result}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc5e770-d494-4d60-a0be-28fa11010dae",
   "metadata": {},
   "source": [
    "**Explanation**\n",
    "\n",
    "**Factorial Function:** The factorial function calculates the factorial of a given number.\n",
    "**ThreadPoolExecutor:** The ThreadPoolExecutor is used to manage a pool of threads. The executor.map method is used to apply the factorial function to each number in the numbers range concurrently.\n",
    "\n",
    "**Result Collection:** The results are collected in a list and printed out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee1bf8f-d6db-46be-9cc8-b05c75e9aaf8",
   "metadata": {},
   "source": [
    "**Q.8 Explain the differences between flipir() and flipud() methods in NurnPy, including their effects on various array dimensions.**\n",
    "\n",
    "**Answer**\n",
    "\n",
    "In NumPy, fliplr() and flipud() are functions used to flip arrays, but they operate along different axes. Here’s a detailed explanation of each:\n",
    "\n",
    "fliplr()\n",
    "* Purpose: Flips the array in the left/right direction.\n",
    "* Axis: Operates along axis 1 (horizontal axis).\n",
    "* Effect: Reverses the order of columns in a 2D array, or the elements along axis 1 in higher-dimensional arrays.\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ad3db56-d3d9-414f-82fe-254dd2300109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 2 1]\n",
      " [6 5 4]\n",
      " [9 8 7]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([[1, 2, 3],\n",
    "              [4, 5, 6],\n",
    "              [7, 8, 9]])\n",
    "\n",
    "B = np.fliplr(A)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a26a5b-3cf0-4b89-b7e4-4ad398acfae8",
   "metadata": {},
   "source": [
    "flipud()\n",
    "* Purpose: Flips the array in the up/down direction.\n",
    "* Axis: Operates along axis 0 (vertical axis).\n",
    "* Effect: Reverses the order of rows in a 2D array, or the elements along axis 0 in higher-dimensional arrays.\n",
    "\n",
    "Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40ae498f-c2df-4278-85ed-f769882a45c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7 8 9]\n",
      " [4 5 6]\n",
      " [1 2 3]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([[1, 2, 3],\n",
    "              [4, 5, 6],\n",
    "              [7, 8, 9]])\n",
    "\n",
    "B = np.flipud(A)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf90248-8f1a-481b-863b-e43f6628b9d6",
   "metadata": {},
   "source": [
    "**Comparison and Effects on Various Dimensions**\n",
    "\n",
    "**1D Arrays:** fliplr() is not applicable as it requires at least a 2D array. flipud() will reverse the elements in a 1D array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3652834b-6485-4601-8119-4fe306cb54a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 2 1]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([1, 2, 3])\n",
    "B = np.flipud(A)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420335bc-df42-47c7-bb2e-4c62d0a7dd68",
   "metadata": {},
   "source": [
    "**2D Arrays:** fliplr() flips the columns, while flipud() flips the rows.\n",
    "\n",
    "**3D Arrays and Higher:** Both functions can be applied, but they will operate along their respective axes. For example, in a 3D array, fliplr() will flip the elements along the second axis, and flipud() will flip the elements along the first axis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591dc7b0-bbed-4d64-9f89-a301c4f49f0f",
   "metadata": {},
   "source": [
    "**Q.9 Discuss the functionality of the array_split() method in NumPy, How does it handle uneven splits?**\n",
    "\n",
    "**Answer**\n",
    "\n",
    "The array_split() method in NumPy is used to split an array into multiple sub-arrays. Unlike the split() method, which requires the array to be split into equal parts, array_split() can handle uneven splits, making it more flexible for various use cases.\n",
    "\n",
    "**Functionality of array_split()**\n",
    "\n",
    "* Basic Usage: The array_split() function takes an array and the number of sections or indices at which to split the array.\n",
    "\n",
    "Syntax: numpy.array_split(ary, indices_or_sections, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1525b6b-733a-4b84-83a6-990a9b630c0d",
   "metadata": {},
   "source": [
    "* ary: The input array to be split.\n",
    "* indices_or_sections: If an integer, it specifies the number of equal or nearly equal sections to split the array into. If a list of indices, it specifies the points at which to split the array.\n",
    "* axis: The axis along which to split the array (default is 0).\n",
    "\n",
    "**Handling Uneven Splits**\n",
    "When the array cannot be evenly divided by the specified number of sections, array_split() ensures that the resulting sub-arrays are as equal in size as possible. It distributes the remainder elements across the sub-arrays.\n",
    "\n",
    "**Example with Integer Sections**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43dc3446-cc34-489b-b318-f43ef8e84269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0, 1, 2]), array([3, 4]), array([5, 6]), array([7, 8])]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create an array of 9 elements\n",
    "x = np.arange(9)\n",
    "\n",
    "# Split the array into 4 sections\n",
    "result = np.array_split(x, 4)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ad0bfd-1965-4a49-aaa9-ac6845617918",
   "metadata": {},
   "source": [
    "**Q.10 Explain the concepts of vectorization and broadcasting in NumPy. How do they contribute to efficient array operations?**\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "**Vectorization in NumPy**\n",
    "\n",
    "Vectorization refers to the process of performing operations on entire arrays rather than individual elements. This approach leverages low-level optimizations and avoids explicit loops in Python, leading to significant performance improvements.\n",
    "\n",
    "**Benefits of Vectorization**\n",
    "* Speed: Vectorized operations are executed in compiled C code, which is much faster than Python loops.\n",
    "* Readability: Code is more concise and easier to read.\n",
    "* Simplicity: Reduces the complexity of the code by eliminating explicit loops.\n",
    "\n",
    "Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64137ce8-940a-4401-a9f5-685fd7fcfdd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2  4  6  8 10]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Using a loop\n",
    "arr = np.array([1, 2, 3, 4, 5])\n",
    "result = np.zeros_like(arr)\n",
    "for i in range(len(arr)):\n",
    "    result[i] = arr[i] * 2\n",
    "\n",
    "# Vectorized operation\n",
    "result = arr * 2\n",
    "print(result)  # Output: [ 2  4  6  8 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a09542-8218-4efc-b275-0b295784fad4",
   "metadata": {},
   "source": [
    "In the example above, the vectorized operation (arr * 2) is much simpler and faster than using a loop.\n",
    "\n",
    "**Broadcasting in NumPy**\n",
    "\n",
    "Broadcasting is a technique that allows NumPy to perform operations on arrays of different shapes. It “stretches” the smaller array across the larger array so that they have compatible shapes for element-wise operations.\n",
    "\n",
    "How Broadcasting Works\n",
    "* Shape Compatibility: Two dimensions are compatible when they are equal or one of them is 1.\n",
    "* Alignment: NumPy aligns the shapes of the arrays starting from the trailing dimensions.\n",
    "\n",
    "Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d29d778e-044a-45d9-bdfe-81b188d84456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11 12 13]\n",
      " [21 22 23]\n",
      " [31 32 33]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([1, 2, 3])\n",
    "b = np.array([[10], [20], [30]])\n",
    "\n",
    "# Broadcasting b to match the shape of a\n",
    "result = a + b\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed332ba-cc6a-4930-9ef7-780979d368c1",
   "metadata": {},
   "source": [
    "In this example, b is broadcasted to match the shape of a, allowing element-wise addition.\n",
    "\n",
    "**Contribution to Efficient Array Operations**\n",
    "\n",
    "* Reduced Memory Usage: Broadcasting avoids making unnecessary copies of data, leading to more efficient memory usage.\n",
    "* Performance: Both vectorization and broadcasting leverage low-level optimizations, resulting in faster execution.\n",
    "* Code Simplicity: These techniques simplify code by eliminating the need for explicit loops and complex indexing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
